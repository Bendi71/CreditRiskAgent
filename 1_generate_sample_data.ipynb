{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9a7b69c2",
      "metadata": {
        "id": "9a7b69c2"
      },
      "source": [
        "# Generate Synthetic Credit Application Data with OpenAI\n",
        "\n",
        "This notebook generates a complete synthetic credit application dataset using OpenAI's GPT-4o mini model. We'll create structured data, unstructured text descriptions, and default outcomes all through AI generation.\n",
        "\n",
        "## Main Objectives\n",
        "- Use OpenAI API to generate realistic credit application data\n",
        "- Create structured financial data through AI prompting\n",
        "- Generate unstructured text descriptions for loan applications\n",
        "- Determine default outcomes using AI reasoning\n",
        "- Store all generated data in JSON format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f562b8c",
      "metadata": {
        "id": "1f562b8c"
      },
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e6c50e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94e6c50e",
        "outputId": "311b6002-eb98-43ca-9ff7-5cd5c3c9d9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.93.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Libraries imported and OpenAI client initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "import random\n",
        "import tiktoken\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Initialize OpenAI client\n",
        "from google.colab import userdata\n",
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "print(\"Libraries imported and OpenAI client initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e14bc6",
      "metadata": {
        "id": "70e14bc6"
      },
      "source": [
        "## Generate Structured Credit Application Data\n",
        "\n",
        "First, let's define the parameters and distributions for our structured data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "682faaa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "682faaa9",
        "outputId": "7b57c4c9-bc9f-43d2-ea09-6145298263ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating structured credit-application data one-by-one …\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 000200: 100%|██████████| 200/200 [08:36<00:00,  2.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✔️  Generated 200 records.\n",
            "Sample:\n",
            "{\n",
            "  \"applicant_id\": \"APP_000001\",\n",
            "  \"age\": 34,\n",
            "  \"income\": 55000,\n",
            "  \"purpose\": \"debt_consolidation\",\n",
            "  \"loan_amount\": 15000,\n",
            "  \"credit_history\": \"fair\",\n",
            "  \"employment_length\": 8.5,\n",
            "  \"debt_to_income\": 0.35,\n",
            "  \"location\": \"CA\",\n",
            "  \"education\": \"bachelors\",\n",
            "  \"criminal_record\": \"no\"\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import json\n",
        "import time\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "from tqdm import tqdm\n",
        "# ── Static, domain-specific reference data ────────────────────────────────────\n",
        "LOAN_PURPOSES = {\n",
        "    \"home_improvement\":  {\"typical_amount_range\": (5_000, 50_000)},\n",
        "    \"debt_consolidation\": {\"typical_amount_range\": (3_000, 30_000)},\n",
        "    \"business\":          {\"typical_amount_range\": (10_000, 100_000)},\n",
        "    \"education\":         {\"typical_amount_range\": (2_000, 25_000)},\n",
        "    \"medical\":           {\"typical_amount_range\": (1_000, 15_000)},\n",
        "    \"vacation\":          {\"typical_amount_range\": (2_000, 15_000)},\n",
        "    \"wedding\":           {\"typical_amount_range\": (3_000, 25_000)},\n",
        "    \"car\":               {\"typical_amount_range\": (5_000, 40_000)},\n",
        "    \"other\":             {\"typical_amount_range\": (1_000, 20_000)}\n",
        "}\n",
        "CREDIT_HISTORY_LEVELS = [ \"good\", \"fair\", \"poor\", \"terrible\"]\n",
        "\n",
        "# ── Low-level helper – generates ONE record ───────────────────────────────────\n",
        "def generate_single_application(app_id: str, client: openai.OpenAI) -> dict | None:\n",
        "    \"\"\"\n",
        "    Call the OpenAI Chat API once to create a single structured credit-application\n",
        "    record whose applicant_id is fixed to `app_id`.  Returns the parsed dict or\n",
        "    None on failure.\n",
        "    \"\"\"\n",
        "    purpose_list = list(LOAN_PURPOSES.keys())\n",
        "    amount_ranges = {k: v[\"typical_amount_range\"] for k, v in LOAN_PURPOSES.items()}\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Generate ONE realistic credit-application record in valid JSON (no markdown fences).\n",
        "    Hard-set the field `applicant_id` to \"{app_id}\".  Vary between good and bad applications,\n",
        "    in the moment the client is applying for a loan the economy can be also in a bad state. I need\n",
        "    you to have an appropriate distribution of good and bad applications.\n",
        "\n",
        "\n",
        "    Other requirements:\n",
        "\n",
        "    • age: 18-80\n",
        "    • income: realistic annual USD income\n",
        "    • purpose: pick from {purpose_list}\n",
        "    • loan_amount: respect these ranges {amount_ranges}\n",
        "    • credit_history: one of {CREDIT_HISTORY_LEVELS}\n",
        "    • employment_length: years (may be float, must be plausible given age)\n",
        "    • debt_to_income: 0.00-1.00\n",
        "    • location: US state abbreviation\n",
        "    • education: none | high_school | some_college | bachelors | masters | phd\n",
        "    • criminal_record: yes | no\n",
        "\n",
        "    Maintain realistic correlations (e.g. higher income ↔ better credit, etc.).\n",
        "    Return ONLY a single JSON object, no surrounding text.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\",\n",
        "                 \"content\": \"You are a financial data generator. Output valid JSON only.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt.strip()}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=800\n",
        "        )\n",
        "\n",
        "        raw = response.choices[0].message.content.strip()\n",
        "        # Remove stray fences if the model adds them\n",
        "        cleaned = raw.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "        return json.loads(cleaned)\n",
        "\n",
        "    except Exception as exc:\n",
        "        print(f\"[{app_id}] - Error: {exc}\")\n",
        "        return None\n",
        "\n",
        "# ── High-level wrapper – generates N records sequentially ─────────────────────\n",
        "def generate_structured_data_with_ai(\n",
        "    n_samples: int = 100,\n",
        "    start_index: int = 1,\n",
        "    pause_secs: float = 0.6\n",
        ") -> list[dict]:\n",
        "    \"\"\"\n",
        "    Loop over `n_samples`, calling the API once per record so partial failures\n",
        "    don’t spoil the whole batch.  Returns a list of successfully generated dicts.\n",
        "    \"\"\"\n",
        "    client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "    records: list[dict] = []\n",
        "    pbar = tqdm(range(start_index, start_index + n_samples))\n",
        "    for i in pbar:\n",
        "        pbar.set_description(f\"Generating {i:06d}\")\n",
        "        pbar.refresh()\n",
        "        app_id = f\"APP_{i:06d}\"\n",
        "        record = generate_single_application(app_id, client)\n",
        "        if record:\n",
        "            records.append(record)\n",
        "        else:\n",
        "            print(f\"[{app_id}] skipped due to error.\")\n",
        "        time.sleep(pause_secs)       # gentle pacing to avoid rate-limit spikes\n",
        "\n",
        "    return records\n",
        "\n",
        "\n",
        "print(\"Generating structured credit-application data one-by-one …\")\n",
        "structured_data = generate_structured_data_with_ai(n_samples=200)\n",
        "\n",
        "if structured_data:\n",
        "    print(f\"\\nSuccessfully generated {len(structured_data)} records.\")\n",
        "    print(\"Sample:\")\n",
        "    print(json.dumps(structured_data[0], indent=2))\n",
        "else:\n",
        "    print(\"No records generated.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9babbb50",
      "metadata": {
        "id": "9babbb50"
      },
      "source": [
        "## Generate Unstructured Text Descriptions\n",
        "\n",
        "Now let's use OpenAI to generate realistic loan application text descriptions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "e124c7ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e124c7ec",
        "outputId": "24d6e920-22cc-4282-dc81-432c53b35b11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating text descriptions for loan applications...\n",
            "Generated 10 text descriptions...\n",
            "Generated 20 text descriptions...\n",
            "Generated 30 text descriptions...\n",
            "Generated 40 text descriptions...\n",
            "Generated 50 text descriptions...\n",
            "Generated 60 text descriptions...\n",
            "Generated 70 text descriptions...\n",
            "Generated 80 text descriptions...\n",
            "Generated 90 text descriptions...\n",
            "Generated 100 text descriptions...\n",
            "Generated 110 text descriptions...\n",
            "Generated 120 text descriptions...\n",
            "Generated 130 text descriptions...\n",
            "Generated 140 text descriptions...\n",
            "Generated 150 text descriptions...\n",
            "Generated 160 text descriptions...\n",
            "Generated 170 text descriptions...\n",
            "Generated 180 text descriptions...\n",
            "Generated 190 text descriptions...\n",
            "Generated 200 text descriptions...\n",
            "Successfully generated text descriptions for 200 records\n",
            "\n",
            "Sample text description:\n",
            "Purpose: debt_consolidation\n",
            "Description: I am seeking a loan of $15,000 for debt consolidation to help streamline my finances and reduce my monthly payments. With a stable income of $55,000 and 8.5 years at my current job, I believe I have a solid foundation to manage this loan despite my fair credit history. My debt-to-income ratio of 0.35 reflects my commitment to responsible financial management, and I am confident in my ability to repay the loan while improving my overall financial health.\n"
          ]
        }
      ],
      "source": [
        "def generate_text_descriptions_with_ai(structured_records):\n",
        "    \"\"\"Generate text descriptions for each credit application using OpenAI\"\"\"\n",
        "\n",
        "    enhanced_records = []\n",
        "\n",
        "    for i, record in enumerate(structured_records):\n",
        "        # Create a detailed prompt for text generation\n",
        "        prompt = f\"\"\"Write a realistic loan application description for this applicant:\n",
        "\n",
        "        Age: {record['age']}\n",
        "        Income: ${record['income']:,}\n",
        "        Loan Amount: ${record['loan_amount']:,}\n",
        "        Purpose: {record['purpose']}\n",
        "        Credit History: {record['credit_history']}\n",
        "        Employment Length: {record['employment_length']} years\n",
        "        Debt-to-Income: {record['debt_to_income']:.2f}\n",
        "        Education: {record['education']}\n",
        "        Location: {record['location']}\n",
        "\n",
        "        Generate a 2-3 sentence description that sounds like a real loan application explanation. Include:\n",
        "        - Why they need the loan\n",
        "        - Brief mention of their financial situation\n",
        "        - Confidence in repayment ability\n",
        "\n",
        "        Make it sound natural and personalized based on their characteristics.\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are writing loan application descriptions. Write realistic, personalized descriptions based on applicant characteristics.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.8,\n",
        "                max_tokens=200\n",
        "            )\n",
        "\n",
        "            # Add text description to record\n",
        "            enhanced_record = record.copy()\n",
        "            enhanced_record['text_description'] = response.choices[0].message.content.strip()\n",
        "            enhanced_records.append(enhanced_record)\n",
        "\n",
        "            # Rate limiting\n",
        "            time.sleep(0.1)\n",
        "\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"Generated {i + 1} text descriptions...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating text for record {i}: {e}\")\n",
        "            # Add record without text description\n",
        "            enhanced_record = record.copy()\n",
        "            enhanced_record['text_description'] = \"Standard loan application request.\"\n",
        "            enhanced_records.append(enhanced_record)\n",
        "\n",
        "    return enhanced_records\n",
        "\n",
        "# Generate text descriptions\n",
        "print(\"Generating text descriptions for loan applications...\")\n",
        "enhanced_data = generate_text_descriptions_with_ai(structured_data)\n",
        "\n",
        "print(f\"Successfully generated text descriptions for {len(enhanced_data)} records\")\n",
        "print(\"\\nSample text description:\")\n",
        "print(f\"Purpose: {enhanced_data[0]['purpose']}\")\n",
        "print(f\"Description: {enhanced_data[0]['text_description']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbc41bc7",
      "metadata": {
        "id": "cbc41bc7"
      },
      "source": [
        "## Generate Default Outcomes Using AI\n",
        "\n",
        "Now let's use OpenAI to determine default outcomes based on all available information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df5de038",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df5de038",
        "outputId": "e56647a5-2b41-43a0-b251-ec5ef0d59823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating default outcomes using token probabilities...\n",
            "Token IDs: D=35, ND=17538\n",
            "Processed 10/200 records\n",
            "Processed 20/200 records\n",
            "Processed 30/200 records\n",
            "Processed 40/200 records\n",
            "Processed 50/200 records\n",
            "Processed 60/200 records\n",
            "Processed 70/200 records\n",
            "Processed 80/200 records\n",
            "Processed 90/200 records\n",
            "Processed 100/200 records\n",
            "Processed 110/200 records\n",
            "Processed 120/200 records\n",
            "Processed 130/200 records\n",
            "Processed 140/200 records\n",
            "Processed 150/200 records\n",
            "Processed 160/200 records\n",
            "Processed 170/200 records\n",
            "Processed 180/200 records\n",
            "Processed 190/200 records\n",
            "Processed 200/200 records\n",
            "Successfully generated token-based risk assessments for 200 records\n",
            "\n",
            "Default Statistics:\n",
            "Average default probability: 0.195\n",
            "Min/Max default probability: 0.000 / 1.000\n",
            "Token predictions: D=39, ND=161\n",
            "\n",
            "Sample record with token probabilities:\n",
            "Applicant: APP_000001\n",
            "Credit History: fair\n",
            "Predicted Token: ND\n",
            "Default Probability: 0.009\n",
            "No Default Probability: 0.991\n"
          ]
        }
      ],
      "source": [
        "def get_token_ids(text, model=\"gpt-4o-mini\"):\n",
        "    \"\"\"Get token IDs for given text\"\"\"\n",
        "    # Use the appropriate encoding for the model\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
        "    return encoding.encode(text)\n",
        "\n",
        "def generate_default_outcomes_with_token_probs(records):\n",
        "    \"\"\"Generate default outcomes using token probabilities for D and ND tokens\"\"\"\n",
        "\n",
        "    # Get token IDs for D and ND\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
        "    d_token_id = encoding.encode(\"D\")[0]  # Default token\n",
        "    nd_token_id = encoding.encode(\"ND\")[0]  # No Default token\n",
        "\n",
        "    print(f\"Token IDs: D={d_token_id}, ND={nd_token_id}\")\n",
        "\n",
        "    final_records = []\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "\n",
        "        # random state, good with 20% prob bad with 80% prob\n",
        "        state = random.choices(['good', 'bad'], weights=[0.2, 0.8])[0]\n",
        "\n",
        "        # Create prompt for binary classification\n",
        "        prompt = f\"\"\"Based on the following credit application, will this customer default on their loan?\n",
        "        Take into account the fact that there are things that the customer might not be disclosing, or that even with average\n",
        "        financial health it is possible to default in bad times.\n",
        "\n",
        "        Assume that the current state of the economy is {state}\n",
        "\n",
        "        Customer Profile:\n",
        "        - Age: {record['age']}\n",
        "        - Annual Income: ${record['income']:,}\n",
        "        - Loan Amount: ${record['loan_amount']:,}\n",
        "        - Purpose: {record['purpose']}\n",
        "        - Credit History: {record['credit_history']}\n",
        "        - Employment Length: {record['employment_length']} years\n",
        "        - Debt-to-Income Ratio: {record['debt_to_income']:.2f}\n",
        "        - Education: {record['education']}\n",
        "        - Location: {record['location']}\n",
        "        - Application Description: {record['text_description']}\n",
        "\n",
        "        Consider standard credit risk factors:\n",
        "        - Credit history quality\n",
        "        - Debt-to-income ratio\n",
        "        - Employment stability\n",
        "        - Income level relative to loan amount\n",
        "        - Loan purpose risk\n",
        "\n",
        "        Respond with only one token: D (for default) or ND (for no default).\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a credit risk analyst. Respond with only 'D' for default or 'ND' for no default.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.1,\n",
        "                max_tokens=1,\n",
        "                logprobs=True,\n",
        "                top_logprobs=10\n",
        "            )\n",
        "\n",
        "            # Get the response token and its logprobs\n",
        "            choice = response.choices[0]\n",
        "\n",
        "            if choice.logprobs and choice.logprobs.content:\n",
        "                # Get the first token's logprobs\n",
        "                token_logprobs = choice.logprobs.content[0]\n",
        "\n",
        "                # Extract probabilities for D and ND tokens\n",
        "                d_logprob = None\n",
        "                nd_logprob = None\n",
        "\n",
        "                # Check the top logprobs for D and ND tokens\n",
        "                for top_logprob in token_logprobs.top_logprobs:\n",
        "                    if top_logprob.token == \"D\":\n",
        "                        d_logprob = top_logprob.logprob\n",
        "                    elif top_logprob.token == \"ND\":\n",
        "                        nd_logprob = top_logprob.logprob\n",
        "\n",
        "                # If we don't find both tokens in top logprobs, use the predicted token\n",
        "                predicted_token = choice.message.content.strip()\n",
        "                if predicted_token == \"D\" and d_logprob is None:\n",
        "                    d_logprob = token_logprobs.logprob\n",
        "                elif predicted_token == \"ND\" and nd_logprob is None:\n",
        "                    nd_logprob = token_logprobs.logprob\n",
        "\n",
        "                # Convert logprobs to probabilities\n",
        "                if d_logprob is not None and nd_logprob is not None:\n",
        "                    d_prob = np.exp(d_logprob)\n",
        "                    nd_prob = np.exp(nd_logprob)\n",
        "\n",
        "                    # Normalize probabilities\n",
        "                    total_prob = d_prob + nd_prob\n",
        "                    d_prob_normalized = d_prob / total_prob\n",
        "                    nd_prob_normalized = nd_prob / total_prob\n",
        "\n",
        "                    default_probability = d_prob_normalized\n",
        "                    no_default_probability = nd_prob_normalized\n",
        "\n",
        "\n",
        "            # Add results to record\n",
        "            enhanced_record = record.copy()\n",
        "            enhanced_record['default_probability'] = round(default_probability, 4)\n",
        "            enhanced_record['no_default_probability'] = round(no_default_probability, 4)\n",
        "            enhanced_record['predicted_token'] = predicted_token if 'predicted_token' in locals() else choice.message.content.strip()\n",
        "\n",
        "            final_records.append(enhanced_record)\n",
        "\n",
        "            # Rate limiting\n",
        "            time.sleep(0.1)\n",
        "\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"Processed {i + 1}/{len(records)} records\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing record {i}: {e}\")\n",
        "            # Add record with default values\n",
        "            enhanced_record = record.copy()\n",
        "            enhanced_record['default_probability'] = 0.1\n",
        "            enhanced_record['no_default_probability'] = 0.9\n",
        "            enhanced_record['default_outcome'] = 0\n",
        "            enhanced_record['predicted_token'] = \"ND\"\n",
        "            final_records.append(enhanced_record)\n",
        "\n",
        "    return final_records\n",
        "\n",
        "# Generate default outcomes using token probabilities\n",
        "print(\"Generating default outcomes using token probabilities...\")\n",
        "complete_data = generate_default_outcomes_with_token_probs(enhanced_data)\n",
        "\n",
        "print(f\"Successfully generated token-based risk assessments for {len(complete_data)} records\")\n",
        "\n",
        "# Display statistics\n",
        "default_probs = [record['default_probability'] for record in complete_data]\n",
        "predicted_tokens = [record['predicted_token'] for record in complete_data]\n",
        "\n",
        "print(f\"\\nDefault Statistics:\")\n",
        "print(f\"Average default probability: {np.mean(default_probs):.3f}\")\n",
        "print(f\"Min/Max default probability: {np.min(default_probs):.3f} / {np.max(default_probs):.3f}\")\n",
        "print(f\"Token predictions: D={predicted_tokens.count('D')}, ND={predicted_tokens.count('ND')}\")\n",
        "\n",
        "# Show sample with token probabilities\n",
        "print(f\"\\nSample record with token probabilities:\")\n",
        "sample = complete_data[0]\n",
        "print(f\"Applicant: {sample['applicant_id']}\")\n",
        "print(f\"Credit History: {sample['credit_history']}\")\n",
        "print(f\"Predicted Token: {sample['predicted_token']}\")\n",
        "print(f\"Default Probability: {sample['default_probability']:.3f}\")\n",
        "print(f\"No Default Probability: {sample['no_default_probability']:.3f}\")\n",
        "\n",
        "final_data = complete_data.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5643b45b",
      "metadata": {
        "id": "5643b45b"
      },
      "source": [
        "## Save Dataset to JSON\n",
        "\n",
        "Let's save our complete dataset to a JSON file for use in subsequent notebooks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Puv9bPWlKR4S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puv9bPWlKR4S",
        "outputId": "cb7f9189-9d32-435e-839a-09b67b08ec49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf557a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaf557a6",
        "outputId": "aae92980-b72c-4c69-f06f-ef904b4d1972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset saved to /content/drive/MyDrive/data/credit_applications_dataset.json\n",
            "Total records: 200\n",
            "File size: 188411 bytes\n",
            "✅ Simplified dataset saved to credit_applications_simple.csv\n",
            "\n",
            "Sample records from final dataset:\n",
            "\n",
            "--- Applicant APP_000001 ---\n",
            "Age: 34, Income: $55,000\n",
            "Loan: $15,000 for debt_consolidation\n",
            "Credit: fair\n",
            "Description: I am seeking a loan of $15,000 for debt consolidation to help streamline my finances and reduce my monthly payments. With a stable income of $55,000 and 8.5 years at my current job, I believe I have a solid foundation to manage this loan despite my fair credit history. My debt-to-income ratio of 0.35 reflects my commitment to responsible financial management, and I am confident in my ability to repay the loan while improving my overall financial health.\n",
            "\n",
            "--- Applicant APP_000002 ---\n",
            "Age: 34, Income: $52,000\n",
            "Loan: $15,000 for debt_consolidation\n",
            "Credit: fair\n",
            "Description: I am a 34-year-old resident of California with a stable job, having been employed for over six years, and I am seeking a $15,000 loan to consolidate my existing debts. My annual income of $52,000 allows me to manage my finances responsibly, although my credit history is fair and my debt-to-income ratio is currently 0.35. I am confident that consolidating my debts will not only simplify my payments but also enhance my ability to repay the loan promptly, paving the way for improved financial health.\n",
            "\n",
            "Sample complete record:\n",
            "applicant_id: APP_000001\n",
            "age: 34\n",
            "income: 55000\n",
            "purpose: debt_consolidation\n",
            "loan_amount: 15000\n",
            "credit_history: fair\n",
            "employment_length: 8.5\n",
            "debt_to_income: 0.35\n",
            "location: CA\n",
            "education: bachelors\n",
            "criminal_record: no\n",
            "text_description: I am seeking a loan of $15,000 for debt consolidation to help streamline my finances and reduce my m...\n",
            "default_probability: 0.0086\n",
            "no_default_probability: 0.9914\n",
            "predicted_token: ND\n"
          ]
        }
      ],
      "source": [
        "# Add metadata to the dataset\n",
        "dataset_metadata = {\n",
        "    \"dataset_info\": {\n",
        "        \"creation_date\": datetime.now().isoformat(),\n",
        "        \"total_records\": len(final_data),\n",
        "        \"generation_method\": \"OpenAI GPT-4o mini\",\n",
        "        \"version\": \"1.0\",\n",
        "        \"description\": \"Synthetic credit application dataset with structured data, text descriptions, and default outcomes\"\n",
        "    },\n",
        "    \"feature_descriptions\": {\n",
        "        \"applicant_id\": \"Unique identifier for each applicant\",\n",
        "        \"age\": \"Age of applicant in years\",\n",
        "        \"income\": \"Annual income in USD\",\n",
        "        \"loan_amount\": \"Requested loan amount in USD\",\n",
        "        \"purpose\": \"Purpose of the loan\",\n",
        "        \"credit_history\": \"Credit history rating (excellent, good, fair, poor)\",\n",
        "        \"employment_length\": \"Years of employment\",\n",
        "        \"debt_to_income\": \"Debt-to-income ratio (0-1)\",\n",
        "        \"text_description\": \"Applicant's loan application narrative\",\n",
        "        \"default_probability\": \"Probability of default (0-1)\",\n",
        "        \"risk_rating\": \"Risk assessment (Low, Medium, High)\",\n",
        "        \"risk_explanation\": \"Explanation of key risk factors\",\n",
        "        \"default_label\": \"Binary outcome (0=no default, 1=default)\"\n",
        "    },\n",
        "}\n",
        "\n",
        "# Complete dataset structure\n",
        "complete_dataset = {\n",
        "    \"metadata\": dataset_metadata,\n",
        "    \"applications\": final_data\n",
        "}\n",
        "\n",
        "output_file = '/content/drive/MyDrive/data/credit_applications_dataset.json'\n",
        "\n",
        "import os, pathlib\n",
        "pathlib.Path(output_file).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Add metadata\n",
        "dataset = {\n",
        "    'metadata': {\n",
        "        'generated_date': datetime.now().isoformat(),\n",
        "        'total_records': len(complete_data),\n",
        "        'generation_method': 'OpenAI GPT-4o mini with token probabilities',\n",
        "        'average_default_probability': np.mean(default_probs),\n",
        "        'prediction_method': 'Token probability for D (Default) and ND (No Default) tokens',\n",
        "        'token_distribution': {\n",
        "            'D_predictions': predicted_tokens.count('D'),\n",
        "            'ND_predictions': predicted_tokens.count('ND')\n",
        "        }\n",
        "    },\n",
        "    'feature_descriptions': {\n",
        "        'applicant_id': 'Unique identifier for each applicant',\n",
        "        'age': 'Age of applicant in years',\n",
        "        'income': 'Annual income in USD',\n",
        "        'loan_amount': 'Requested loan amount in USD',\n",
        "        'purpose': 'Purpose of the loan',\n",
        "        'credit_history': 'Credit history rating (excellent, good, fair, poor)',\n",
        "        'employment_length': 'Years of employment',\n",
        "        'debt_to_income': 'Debt-to-income ratio (0-1)',\n",
        "        'location': 'US state abbreviation',\n",
        "        'education': 'Education level',\n",
        "        'text_description': 'Applicant loan application narrative',\n",
        "        'default_probability': 'Normalized probability of default from D token',\n",
        "        'no_default_probability': 'Normalized probability of no default from ND token',\n",
        "        'default_outcome': 'Binary outcome (0=no default, 1=default)',\n",
        "        'predicted_token': 'Token predicted by model (D or ND)'\n",
        "    },\n",
        "    'data': complete_data\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(dataset, f, indent=2)\n",
        "\n",
        "print(f\"Dataset saved to {output_file}\")\n",
        "print(f\"Total records: {len(complete_data)}\")\n",
        "print(f\"File size: {os.path.getsize(output_file)} bytes\")\n",
        "\n",
        "# Also save a simplified CSV for quick analysis\n",
        "df_simple = pd.DataFrame(final_data)\n",
        "df_simple.to_csv(\"credit_applications_simple.csv\", index=False)\n",
        "print(f\"Simplified dataset saved to credit_applications_simple.csv\")\n",
        "\n",
        "# Display sample records\n",
        "print(\"\\nSample records from final dataset:\")\n",
        "for i in range(2):\n",
        "    print(f\"\\n--- Applicant {final_data[i]['applicant_id']} ---\")\n",
        "    print(f\"Age: {final_data[i]['age']}, Income: ${final_data[i]['income']:,}\")\n",
        "    print(f\"Loan: ${final_data[i]['loan_amount']:,} for {final_data[i]['purpose']}\")\n",
        "    print(f\"Credit: {final_data[i]['credit_history']}\")\n",
        "    print(f\"Description: {final_data[i]['text_description']}\")\n",
        "\n",
        "# Display sample complete record\n",
        "print(\"\\nSample complete record:\")\n",
        "sample_record = complete_data[0]\n",
        "for key, value in sample_record.items():\n",
        "    if key == 'text_description':\n",
        "        print(f\"{key}: {value[:100]}...\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9e0deb5",
      "metadata": {
        "id": "b9e0deb5"
      },
      "source": [
        "## Validate Generated Data\n",
        "\n",
        "Let's perform a quick validation of our generated dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "5cf32c8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cf32c8f",
        "outputId": "ce4f5070-bed7-4542-bf94-842a0bf0c531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset validation:\n",
            "Metadata: {'generated_date': '2025-07-10T07:57:38.514066', 'total_records': 200, 'generation_method': 'OpenAI GPT-4o mini with token probabilities', 'average_default_probability': 0.1952205, 'prediction_method': 'Token probability for D (Default) and ND (No Default) tokens', 'token_distribution': {'D_predictions': 39, 'ND_predictions': 161}}\n",
            "Number of records: 200\n",
            "\n",
            "DataFrame shape: (200, 15)\n",
            "Columns: ['applicant_id', 'age', 'income', 'purpose', 'loan_amount', 'credit_history', 'employment_length', 'debt_to_income', 'location', 'education', 'criminal_record', 'text_description', 'default_probability', 'no_default_probability', 'predicted_token']\n",
            "\n",
            "Numerical statistics:\n",
            "              age        income   loan_amount  employment_length  \\\n",
            "count  200.000000    200.000000    200.000000         200.000000   \n",
            "mean    34.010000  60585.000000  14790.000000           7.672500   \n",
            "std      1.147381   8893.720612   1091.723086           1.774327   \n",
            "min     29.000000  45000.000000  12000.000000           2.500000   \n",
            "25%     34.000000  55000.000000  15000.000000           6.500000   \n",
            "50%     34.000000  58000.000000  15000.000000           8.500000   \n",
            "75%     34.000000  65750.000000  15000.000000           8.500000   \n",
            "max     45.000000  75000.000000  20000.000000          10.500000   \n",
            "\n",
            "       debt_to_income  default_probability  \n",
            "count      200.000000            200.00000  \n",
            "mean         0.334150              0.19522  \n",
            "std          0.034237              0.32155  \n",
            "min          0.250000              0.00000  \n",
            "25%          0.350000              0.00000  \n",
            "50%          0.350000              0.00465  \n",
            "75%          0.350000              0.32080  \n",
            "max          0.450000              1.00000  \n",
            "\n",
            "Categorical distributions:\n",
            "\n",
            "purpose:\n",
            "purpose\n",
            "debt_consolidation    200\n",
            "Name: count, dtype: int64\n",
            "\n",
            "credit_history:\n",
            "credit_history\n",
            "fair    185\n",
            "good     14\n",
            "poor      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "education:\n",
            "education\n",
            "bachelors       171\n",
            "some_college     29\n",
            "Name: count, dtype: int64\n",
            "\n",
            "location:\n",
            "location\n",
            "CA    200\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Dataset generation completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Load and validate the saved dataset\n",
        "with open(output_file, 'r') as f:\n",
        "    loaded_dataset = json.load(f)\n",
        "\n",
        "print(\"Dataset validation:\")\n",
        "print(f\"Metadata: {loaded_dataset['metadata']}\")\n",
        "print(f\"Number of records: {len(loaded_dataset['data'])}\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "df = pd.DataFrame(loaded_dataset['data'])\n",
        "print(f\"\\nDataFrame shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# Basic statistics\n",
        "print(f\"\\nNumerical statistics:\")\n",
        "numerical_cols = ['age', 'income', 'loan_amount', 'employment_length', 'debt_to_income', 'default_probability']\n",
        "print(df[numerical_cols].describe())\n",
        "\n",
        "# Categorical distributions\n",
        "print(f\"\\nCategorical distributions:\")\n",
        "categorical_cols = ['purpose', 'credit_history', 'education', 'location']\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(df[col].value_counts().head())\n",
        "\n",
        "print(f\"\\nDataset generation completed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "tliUN4F-LGYv",
      "metadata": {
        "id": "tliUN4F-LGYv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
